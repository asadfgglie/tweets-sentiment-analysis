{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a3d8f43-08c0-4a85-9164-7a5ba91a5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51b4a3a4-b2db-4278-94f8-f75688d50ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ardia\\AppData\\Local\\Temp\\ipykernel_25628\\949210653.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dh['target'] = dh['target'].replace(target_mapping)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "dh = pd.read_csv(\"clear_lemmatize_expand_texts.csv\")\n",
    "dh = dh[dh['text'].notna()]\n",
    "\n",
    "# Preprocess targets\n",
    "dh['target'] = dh['target'].astype(str)\n",
    "target_mapping = {'0': 0, '4': 1}\n",
    "dh['target'] = dh['target'].replace(target_mapping)\n",
    "\n",
    "# Split text into words\n",
    "dh['text'] = dh['text'].apply(lambda x: x.split())\n",
    "\n",
    "# Create Word2Vec model\n",
    "w2v_model = Word2Vec(dh['text'], vector_size=500, window=3, min_count=1, workers=6)\n",
    "\n",
    "# Function to convert a list of words into a Word2Vec vector\n",
    "def w2v_vectorizer(text):\n",
    "    return np.mean([w2v_model.wv[word] for word in text if word in w2v_model.wv], axis=0)\n",
    "\n",
    "# Apply vectorizer to the text data\n",
    "X_train, X_test, y_train, y_test = train_test_split(dh['text'], dh['target'], test_size=0.991, random_state=42)\n",
    "\n",
    "X_train_w2v = np.array([w2v_vectorizer(text) for text in X_train])\n",
    "X_test_w2v = np.array([w2v_vectorizer(text) for text in X_test])\n",
    "\n",
    "# Find the longest sentence in the dataset\n",
    "longest_sentence = max(dh['text'], key=len)\n",
    "longest_sentence_w2v = w2v_vectorizer(longest_sentence).reshape(1, -1)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=2024),\n",
    "    'Extra Trees': ExtraTreesClassifier(),\n",
    "    'XGBoost': XGBClassifier(eval_metric=[\"error\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b63c823-a489-4076-9c1f-e82e8ecfc090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy for Logistic Regression : 0.7502783189535207, time: 0.6957638263702393\n",
      "test eval time: 1.9268624782562256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ardia\\AppData\\Local\\Temp\\ipykernel_25628\\1085262523.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, pd.DataFrame([result_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy for Random Forest : 0.9998608405232396, time: 28.207966327667236\n",
      "test eval time: 30.68875241279602\n",
      "Training accuracy for Decision Tree : 0.9998608405232396, time: 8.305766344070435\n",
      "test eval time: 0.7030081748962402\n",
      "Training accuracy for Extra Trees : 0.9998608405232396, time: 5.352341651916504\n",
      "test eval time: 35.556556224823\n",
      "Training accuracy for XGBoost : 0.999234622877818, time: 3.507412910461426\n",
      "test eval time: 1.2194581031799316\n",
      "                 Model  Test Accuracy Std  Mean Inference Time  \\\n",
      "0  Logistic Regression       0.738771   0             0.000041   \n",
      "1        Random Forest       0.694244   0             0.001898   \n",
      "2        Decision Tree       0.588495   0             0.000048   \n",
      "3          Extra Trees       0.690709   0             0.001922   \n",
      "4              XGBoost       0.709614   0             0.000393   \n",
      "\n",
      "   Inference Time Std  \n",
      "0            0.000201  \n",
      "1            0.001038  \n",
      "2            0.000220  \n",
      "3            0.000732  \n",
      "4            0.000562  \n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['Model', 'Test Accuracy', 'Std', 'Mean Inference Time', 'Inference Time Std'])\n",
    "\n",
    "for clf_name, classifier in classifiers.items():\n",
    "    # Train the classifier\n",
    "    t1 = time.time()\n",
    "    classifier.fit(X_train_w2v, y_train)\n",
    "    train_accuracy = classifier.score(X_train_w2v, y_train)\n",
    "    print(f\"Training accuracy for {clf_name} : {train_accuracy}, time: {time.time() - t1}\")\n",
    "\n",
    "    # Test accuracy\n",
    "    t1 = time.time()\n",
    "    test_accuracy = accuracy_score(y_test, classifier.predict(X_test_w2v))\n",
    "    print(f\"test eval time: {time.time() - t1}\")\n",
    "\n",
    "    # Measure inference time for the longest sentence\n",
    "    inference_times = []\n",
    "    for _ in range(10000):\n",
    "        t1 = time.time()\n",
    "        classifier.predict(longest_sentence_w2v)\n",
    "        inference_times.append(time.time() - t1)\n",
    "\n",
    "    mean_inference_time = np.mean(inference_times)\n",
    "    std_inference_time = np.std(inference_times)\n",
    "    \n",
    "    result_dict = {\n",
    "        'Model': clf_name,\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Std': 0,  # Placeholder, replace if you have a standard deviation for test accuracy\n",
    "        'Mean Inference Time': mean_inference_time,\n",
    "        'Inference Time Std': std_inference_time\n",
    "    }\n",
    "    results = pd.concat([results, pd.DataFrame([result_dict])], ignore_index=True)\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
